{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed830aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19144\\3510566465.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69a1efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#베이스라인 모델 학습을 위한 준비\n",
    "import torch\n",
    "\n",
    "USE_CUDA=torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "BATCH_SIZE =256\n",
    "EPOCH=30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([64,64]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],\n",
    "                            [0.229,0.224,0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([64,64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir='C:/Users/user/Desktop/kang/spliteed'\n",
    "image_datasets= {x:ImageFolder(root=os.path.join(data_dir,x), transform=data_transforms[x]) for x in ['train','val']}\n",
    "dataloaders= {x:torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train','val']}\n",
    "dataset_sizes= {x: len(image_datasets[x]) for x in ['train','val']}\n",
    "class_names=image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b4a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Trained Model 불러오기\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "num_ftrs=resnet.fc.in_features\n",
    "resnet.fc=nn.Linear(num_ftrs,33)\n",
    "resnet=resnet.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft=optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fb6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Trained Model 일부 Layer Freeze 하기\n",
    "ct=0\n",
    "for child in resnet.children():\n",
    "    ct+=1\n",
    "    if ct<6:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b6313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer Learning 모델 학습과 검증을 위한 함수\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    best_mode_wts=copy.deepcopy(model.state_dict())\n",
    "    best_acc=0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        since=time.time()\n",
    "        \n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss=0.0\n",
    "            running_corrects=0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs= inputs.to(DEVICE)\n",
    "                labels= labels.to(DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds= torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                l_r=[x['lr'] for x in optimizer_ft.param_groups]\n",
    "                print('learning rate:', l_r)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc= running_corrects.double()/dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase=='val' and epoch_acc > best_acc :\n",
    "                best_acc=epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        time_elapsed =time.time()-since\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed % 60))\n",
    "        \n",
    "    model.load_state_dict(best_model_wts)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea743a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "learning rate: [0.001]\n",
      "train Loss: 0.1660 Acc: 0.9466\n",
      "val Loss: 0.1411 Acc: 0.9532\n",
      "Completed in 0m 50s\n",
      "epoch 2\n",
      "learning rate: [0.001]\n",
      "train Loss: 0.1301 Acc: 0.9583\n",
      "val Loss: 0.1590 Acc: 0.9527\n",
      "Completed in 0m 50s\n",
      "epoch 3\n",
      "learning rate: [0.001]\n",
      "train Loss: 0.1151 Acc: 0.9619\n",
      "val Loss: 0.1565 Acc: 0.9483\n",
      "Completed in 0m 51s\n",
      "epoch 4\n",
      "learning rate: [0.001]\n",
      "train Loss: 0.1020 Acc: 0.9677\n",
      "val Loss: 0.1492 Acc: 0.9544\n",
      "Completed in 0m 50s\n",
      "epoch 5\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0952 Acc: 0.9690\n",
      "val Loss: 0.1324 Acc: 0.9574\n",
      "Completed in 0m 50s\n",
      "epoch 6\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0503 Acc: 0.9840\n",
      "val Loss: 0.0451 Acc: 0.9861\n",
      "Completed in 0m 50s\n",
      "epoch 7\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0332 Acc: 0.9898\n",
      "val Loss: 0.0434 Acc: 0.9854\n",
      "Completed in 0m 50s\n",
      "epoch 8\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0259 Acc: 0.9921\n",
      "val Loss: 0.0366 Acc: 0.9889\n",
      "Completed in 0m 51s\n",
      "epoch 9\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0243 Acc: 0.9917\n",
      "val Loss: 0.0392 Acc: 0.9886\n",
      "Completed in 0m 50s\n",
      "epoch 10\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0211 Acc: 0.9926\n",
      "val Loss: 0.0381 Acc: 0.9876\n",
      "Completed in 0m 51s\n",
      "epoch 11\n",
      "learning rate: [0.0001]\n",
      "train Loss: 0.0195 Acc: 0.9933\n",
      "val Loss: 0.0329 Acc: 0.9876\n",
      "Completed in 0m 50s\n",
      "epoch 12\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0156 Acc: 0.9946\n",
      "val Loss: 0.0334 Acc: 0.9896\n",
      "Completed in 0m 46s\n",
      "epoch 13\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0166 Acc: 0.9948\n",
      "val Loss: 0.0319 Acc: 0.9891\n",
      "Completed in 0m 46s\n",
      "epoch 14\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0137 Acc: 0.9957\n",
      "val Loss: 0.0322 Acc: 0.9885\n",
      "Completed in 0m 46s\n",
      "epoch 15\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0151 Acc: 0.9947\n",
      "val Loss: 0.0290 Acc: 0.9900\n",
      "Completed in 0m 46s\n",
      "epoch 16\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0146 Acc: 0.9955\n",
      "val Loss: 0.0311 Acc: 0.9901\n",
      "Completed in 0m 46s\n",
      "epoch 17\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0138 Acc: 0.9952\n",
      "val Loss: 0.0336 Acc: 0.9895\n",
      "Completed in 0m 47s\n",
      "epoch 18\n",
      "learning rate: [1e-05]\n",
      "train Loss: 0.0137 Acc: 0.9951\n",
      "val Loss: 0.0296 Acc: 0.9904\n",
      "Completed in 0m 46s\n",
      "epoch 19\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0140 Acc: 0.9952\n",
      "val Loss: 0.0302 Acc: 0.9896\n",
      "Completed in 0m 47s\n",
      "epoch 20\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0137 Acc: 0.9957\n",
      "val Loss: 0.0292 Acc: 0.9902\n",
      "Completed in 0m 46s\n",
      "epoch 21\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0136 Acc: 0.9958\n",
      "val Loss: 0.0323 Acc: 0.9905\n",
      "Completed in 0m 46s\n",
      "epoch 22\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0121 Acc: 0.9964\n",
      "val Loss: 0.0309 Acc: 0.9896\n",
      "Completed in 0m 46s\n",
      "epoch 23\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0129 Acc: 0.9959\n",
      "val Loss: 0.0301 Acc: 0.9895\n",
      "Completed in 0m 46s\n",
      "epoch 24\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0130 Acc: 0.9956\n",
      "val Loss: 0.0285 Acc: 0.9906\n",
      "Completed in 0m 46s\n",
      "epoch 25\n",
      "learning rate: [1.0000000000000002e-06]\n",
      "train Loss: 0.0128 Acc: 0.9960\n",
      "val Loss: 0.0290 Acc: 0.9907\n",
      "Completed in 0m 46s\n",
      "epoch 26\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0138 Acc: 0.9952\n",
      "val Loss: 0.0296 Acc: 0.9901\n",
      "Completed in 0m 46s\n",
      "epoch 27\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0129 Acc: 0.9958\n",
      "val Loss: 0.0283 Acc: 0.9904\n",
      "Completed in 0m 46s\n",
      "epoch 28\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0121 Acc: 0.9962\n",
      "val Loss: 0.0298 Acc: 0.9914\n",
      "Completed in 0m 46s\n",
      "epoch 29\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0131 Acc: 0.9958\n",
      "val Loss: 0.0319 Acc: 0.9886\n",
      "Completed in 0m 46s\n",
      "epoch 30\n",
      "learning rate: [1.0000000000000002e-07]\n",
      "train Loss: 0.0125 Acc: 0.9960\n",
      "val Loss: 0.0289 Acc: 0.9902\n",
      "Completed in 0m 46s\n"
     ]
    }
   ],
   "source": [
    "#모델 학습 실행하기\n",
    "model_resnet50 = train_resnet(resnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH)\n",
    "torch.save(model_resnet50, 'resnet50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763956f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
